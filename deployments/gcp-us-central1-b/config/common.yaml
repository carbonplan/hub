pangeo:
  jupyterhub:
    scheduling:
    #   userPods:
    #     nodeAffinity:
    #       matchNodePurpose: require
      corePods:
        nodeAffinity:
          matchNodePurpose: require
    singleuser:
    #   initContainers:
    #     - name: volume-mount-hack
    #       image: busybox
    #       command: ["sh", "-c", "id && chown 1000:1000 /home/jovyan && ls -lhd /home/jovyan"]
    #       securityContext:
    #         runAsUser: 0
    #       volumeMounts:
    #       - name: home
    #         mountPath: /home/jovyan
    #         subPath: "home/hub.carbonplan.org/{username}"
    #   storage:
    #     type: static
    #     static:
    #       pvcName: home-nfs
    #       subPath: "home/hub.carbonplan.org/{username}"
      cloudMetadata:
        enabled: true
      cpu:
        limit: 4
        guarantee: 1
      memory:
        limit: 14G
        guarantee: 4G

    hub:
      resources:
        requests:
          cpu: "0.25"
          memory: 0.5Gi
        limits:
          cpu: "1.25"
          memory: 1Gi
      extraConfig:
        profile_list: |
          c.KubeSpawner.profile_list = [
            {
                'display_name': 'small (n1-highmem-2 | 2 cores, 12GB)',
                'kubespawner_override': {
                    'cpu_limit': 2,
                    'cpu_guarantee': 2,
                    'mem_limit': '12G',
                    'mem_guarantee': '12G',
                }
            },
            {
                'display_name': 'standard (n1-highmem-4 | 4 cores, 24GB)',
                'kubespawner_override': {
                    'cpu_limit': 4,
                    'cpu_guarantee': 4,
                    'mem_limit': '24G',
                    'mem_guarantee': '24G',
                }
            },
            {
                'display_name': 'large (n1-highmem-8 | 8 cores, 52GB)',
                'kubespawner_override': {
                    'cpu_limit': 8,
                    'cpu_guarantee': 2,
                    'mem_limit': '50G',
                    'mem_guarantee': '26G',
                }
            },
          ]

        # customPodHook: |
        #   c.JupyterHub.template_paths = ['/usr/local/share/jupyterhub/custom_templates/']
        #   c.JupyterHub.template_vars = {
        #     'pangeo_hub_title': 'hub.carbonplan.org',
        #     'pangeo_hub_subtitle': 'Research Hub for CarbonPlan',
        #     'pangeo_welcome': """Welcome to hub.carbonplan.org. This hub lives in Google Cloud region <code>us-central1-b</code>."""
        #   }

    #   extraVolumes:
    #     - name: custom-templates
    #       gitRepo:
    #         repository: "https://github.com/carbonplan/carbonplan-custom-jupyterhub-templates.git"
    #         revision: "f83bd9a773f1cf8ded69ffb43fdaed20029e318b"
    #   extraVolumeMounts:
    #     - mountPath: /usr/local/share/jupyterhub/custom_templates
    #       name: custom-templates
    #       subPath: "carbonplan-custom-jupyterhub-templates/templates"
    #     - mountPath: /usr/local/share/jupyterhub/static/extra-assets
    #       name: custom-templates
    #       subPath: "carbonplan-custom-jupyterhub-templates/extra-assets"

    auth:
      type: custom
      custom:
        className: oauthenticator.generic.GenericOAuthenticator
        config:
          login_service: "auth0"
          token_url: https://carbonplan.auth0.com/oauth/token
          userdata_url: https://carbonplan.auth0.com/oauth/userinfo
          userdata_method: GET
          username_key: nickname
          scope:
            - openid
            - profile
            - email
      admin:
        access: true
        users:
          - jhamman
          - freeman-lab
  dask-gateway:
    gateway:
      extraConfig:
        # Use the mapping form, to support merging multiple values.yaml
        optionHandler: |
          from dask_gateway_server.options import Options, Integer, Float, String
          def option_handler(options):
              if ":" not in options.image:
                  raise ValueError("When specifying an image you must also provide a tag")
              return {
                  "worker_cores_limit": options.worker_cores,
                  "worker_cores": min(options.worker_cores / 2, 1),
                  "worker_memory": "%fG" % options.worker_memory,
                  "image": options.image,
              }
          c.Backend.cluster_options = Options(
              Integer("worker_cores", 2, min=1, max=4, label="Worker Cores"),
              Float("worker_memory", 8, min=1, max=128, label="Worker Memory (GiB)"),
              String("image", default="carbonplan/notebook:latest", label="Image"),
              handler=option_handler,
          )
      backend:
        worker:
          extraPodConfig:
            tolerations:
              - key: "cloud.google.com/gke-preemptible"
                operator: "Equal"
                value: "true"
                effect: "NoSchedule"
    #     scheduler:
    #       extraPodConfig:
    #         affinity:
    #           nodeAffinity:
    #             requiredDuringSchedulingIgnoredDuringExecution:
    #               nodeSelectorTerms:
    #                 - matchExpressions:
    #                   - key: cloud.google.com/gke-preemptible
    #                     operator: DoesNotExist
    #                   - key: hub.jupyter.org/node-purpose
    #                     operator: In
    #                     values:
    #                     - "user"

# homeDirectories:
#   nfs:
#     enabled: true
#     serverPath: "/homes"
#     # Output from gcloud beta filestore instances describe dev-home --location=us-central1-b
#     serverIP: 10.171.161.186
#     serverName: test
